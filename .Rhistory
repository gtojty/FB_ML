data<-c("hello there, how're you","What's the time jack?", "eat your greens")
require(tm)
s3<-data
dtm <- Corpus(VectorSource(s3)) %>% DocumentTermMatrix(control = list(weighting = weightTfIdf))
require(dplyr)
dtm <- Corpus(VectorSource(s3)) %>% DocumentTermMatrix(control = list(weighting = weightTfIdf))
dtm
inspect(dtm)
as.data.frame(inspect(dtm))
dtm <- Corpus(VectorSource(s3)) %>% DocumentTermMatrix(control = list(weighting = none))
dtm <- Corpus(VectorSource(s3)) %>% DocumentTermMatrix(control = list())
dtm
inspect(dtm)
setwd("/Users/rdavidson/Downloads/")
new_list  <- read.delim(file='Data_set_S1.txt', header=FALSE, stringsAsFactors=FALSE)
names(new_list) <- c('word', 'happiness_rank','happiness_average','happiness_sd','twitter_rank','google_rank','nyt_rank','lyrics_rank')
new_list$word <- tolower(new_list$word)
terms <- new_list$word
terms
head(new_list)
tail(new_list)
library(topicmodels)
install.packages('topicmodels')
library(topicmodels)
require(magrittr)
require(tm)
library(RTextTools)
install.packages('RTextTools')
?aggregate
#source https://eight2late.wordpress.com/2015/09/29/a-gentle-introduction-to-topic-modeling-using-r/
#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Number of topics
k <- 20
setwd("/Users/rdavidson/Dropbox/myPersonality/LDA")
list.files()
swl<-read.csv("user_all_status_swl.csv")
head(swl)
sam<-swl[sample(nrow(swl),100),]
ss<- sam$status
tolower(iconv(ss,"ISO-8859-1","UTF-8"))
ss <- gsub("\\d", "", ss)
ss <- gsub("\\W", " ", ss)
ss <- gsub("[[:punct:]]"," ", ss)
ss <- gsub("bobsnewline", "", ss)
#source https://eight2late.wordpress.com/2015/09/29/a-gentle-introduction-to-topic-modeling-using-r/
#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Number of topics
k <- 20
#Run LDA using Gibbs sampling
dtm <- create_matrix(ss, language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
require(tm)
dtm <- create_matrix(ss, language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
library(RTextTools)
dtm <- create_matrix(ss, language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
dtm<- removeSparseTerms(dtm, .99)
dtm
inspect(dtm)
dtm <- create_matrix(ss, language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
dtm
dtm<- removeSparseTerms(dtm, .99)
dtm
rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm.new   <- dtm[rowTotals> 0, ]
dtm.new
ldaOut <-LDA(dtm.new,k, method= "Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
ldaOut
inspect(ldaOut)
ldaOut.topics <- as.matrix(topics(ldaOut))
write.csv(ldaOut.topics,file=paste("LDAGibbs",k,"DocsToTopics.csv"))
#top 6 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
ldaOut.terms
ldaOut.topics
cbind(ss, ldaOut.topics)
dim(ldaOut.terms)
dim(ldaOut.topics)
dim(ss)
class(ss)
ss
ldaOut.topics
ldaOut.terms
dtm
inspect(dtm)
ss
ldaOut.topics
ldaOut
topics(ldaOut)
dtm.new
intersect(ldaOut.topics[1],1:100)
ldaOut.topics[,1]
ldaOut.topics[,0]
intersect(ldaOut.topics[0],1:100)
intersect(as.numeric(ldaOut.topics[0]),1:100)
class(ldaOut.topics[,0])
intersect(as.numeric(ldaOut.topics[,0]),1:100)
class(as.numeric(ldaOut.topics[,0]))
as.numeric(ldaOut.topics[,0])
dim(ldaOut.topics)
rownames(ldaOut.topics)
as.numeric(rownames(ldaOut.topics))
intersect(as.numeric(rownames(ldaOut.topics)),1:100)
setdiff(as.numeric(rownames(ldaOut.topics)),1:100)
setdiff(1:100,as.numeric(rownames(ldaOut.topics)))
ldaOut.topics[1,]
ldaOut.topics[2,]
ldaOut.topics[9,]
as.data.frame(ldaOut.topics)
as.data.frame(ldaOut.topics)[,1]
as.data.frame(ldaOut.topics)[,0]
as.data.frame(ldaOut.topics)[,2]
as.data.frame(ldaOut.topics)[,1]
ss
ss[rownames(ldaOut.topics),]
ss[rownames(ldaOut.topics)]
ss[as.numeric(rownames(ldaOut.topics))]
sam
sam[1,]
cbind(sam[as.numeric(rownames(ldaOut.topics)),], ldaOut.topics)
output<-cbind(sam[as.numeric(rownames(ldaOut.topics)),], ldaOut.topics)
head(output)
aggregate(ldaOut.topics~user_id, output)
aggregate(ldaOut.topics~user_id, output, FUN=c())
aggregate(ldaOut.topics~user_id, output, FUN=c
)
aggregate(ldaOut.topics~user_id, output, FUN=c)
output<-cbind(sam[as.numeric(rownames(ldaOut.topics)),], ldaOut.topics)
bob<-data.frame(user=c(1,2,1,1,3,2),score=c(4,5,62,3,2,1))
bob
aggregate(score~user, bob,FUN=c)
aggregate(score~user, bob,FUN=c)[1,2]
ldaOut.topics
ldaOut.terms
ldaOut
LDA?
?LDA
ldaOut.gamma
ldaOut@gamma
output<-cbind(sam[as.numeric(rownames(ldaOut.topics)),], ldaOut@gamma)
head(output)
bob<-data.frame(user=c(1,2,1,1,3,2),score=c(4,5,62,3,2,1),score2=c(2,3,4,1,2,3))
bob
aggregate(user,bob)
aggregate(bob)
aggregate(user~score+score2,bob)
aggregate(user~score+score2,bob,colSums)
aggregate(user~c(score,score2),bob,colSums)
?aggregate
aggregate(cbind(score, score2)~user,bob)
aggregate(cbind(score, score2)~user,bob,FUN=colSums)
aggregate(cbind(score, score2)~user,bob,FUN=rbind)
bob
aggregate(cbind(score, score2)~user,bob,FUN=mean)
aggregate(cbind(score, score2)~user,bob,FUN=sum)
aggregate(user,bob,FUN=sum)
colnames(output)
aggregate(bob, by=user)
aggregate(bob, by=user,FUN=sum)
aggregate(bob, by='user',FUN=sum)
aggregate(bob, by=bob$user,FUN=sum)
aggregate(bob, by=as.list(bob$user),FUN=sum)
as.list(bob$user)
aggregate(bob, user,FUN=sum)
aggregate(bob, 'user',FUN=sum)
aggregate(bob, bob$user,FUN=sum)
bob$user
c(bob$user)
unlist(bob$user)
head(ldaOut@gamma)
aggregate(cbind("1","2")~user_id,output,FUN=sum)
rownames(output)
colnames(output)
colnames(output)[-"X"]
colnames(output)[1]
colnames(output)[c(-1,-2,-3)]
aggregate(colnames(output)[c(-1,-2,-3)]~user_id,output,FUN=colSums)
aggregate(cbind(colnames(output)[c(-1,-2,-3)])~user_id,output,FUN=colSums)
aggregate(cbind(colnames(output[c(-1,-2,-3)]))~user_id,output,FUN=colSums)
library(plyr)
ddply(bob,.(score,score2), transform, new=score/score2)
ddply(bob,.(score,score2), transform, new=colSums(cbind(score,score2)))
?ddply
ddply(bob, .(user),.fun=colSums,)
ddply(bob, .(user),colSums,)
ddply(bob, .(user),colSums,score, score2)
ddply(bob, .(user),colSums,c(score, score2))
ddply(bob, .(user),colSums,cbind(score, score2))
ddply(bob, .(user),sum)
ddply(bob, user~score,sum)
ddply(bob, score~user,sum)
aggregate(cbind(score,score2)~user,bob)
aggregate(cbind(score,score2)~user,bob,sum)
aggregate(cbind("1","2")~user_id,output,sum)
aggregate(cbind(1,2)~user_id,output,sum)
colnames(output)
paste("topic",1:k)
colnames(output)<-c("X","user_id","status",paste("topic",1:k))
aggregate(cbind(paste("topic",1:k))~user_id,output,sum)
bob
colnames(bob)<-c("user",paste("score",1:2)
)
bob
aggregate(cbind(paste("score",1:2))~user,bob,sum)
colnames(bob)<-c("user",paste("score",1:2, sep=""))
bob
aggregate(cbind(score1,score2)~user,bob,sum)
colnames(output)
colnames(output)<-c("X","user_id","status",paste("topic",1:k,sep=""))
aggregate(cbind(topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8,topic9,topic10,topic11,topic12,topic13,topic14,topic15,topic16,topic17,topic18,topic19,topic20)~user_id, output, FUN=sum)
output_aggregate<-aggregate(cbind(topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8,topic9,topic10,topic11,topic12,topic13,topic14,topic15,topic16,topic17,topic18,topic19,topic20)~user_id, output, FUN=sum)
head(output_aggregate)
dtm
t2 <- aggregate(status~user_id, swl_status2, FUN= paste, collape=' ')
swl_status2<-swl
t2 <- aggregate(status~user_id, swl_status2, FUN= paste, collape=' ')
#take one user
sam <- t2[sample(nrow(t2),1), ]
#remove punctuations and stuffs
ss<- as.vector(sam$status)
ss <- tolower(ss)
ss <- gsub("\\d", "", ss)
ss <- gsub("\\W", " ", ss)
ss <- gsub("[[:punct:]]"," ", ss)
ss <- gsub("bobsnewline", "", ss)
#create dtm for each user, finally I know how to use Tfidf
dtm1 <- create_matrix(ss, language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTfIdf)
#turn dtm into a frequency table
freqs <- as.data.frame(inspect(dtm1))
dtm1
freqs <- colSums(freqs)
freqs
#the list of topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
#just get one topic, a topic has 20 terms
avector <- ldaOut.terms[,1]
ldaOut.terms
freqs_sub <- freqs[avector]
freqs_sub
freqs
intersect(avector, colnames(freqs))
colnames(freqs)
freqs
class(freqs)
rownames(freqs)
dim(freqs)
freqs[1,]
freqs[1]
class(freqs[1])
freqs[absenc]
freqs['absenc']
avector
dtm1 <- create_matrix(ss, language="english", removeNumbers=TRUE, weighting=weightTfIdf)
dtm1
t2 <- aggregate(status~user_id, swl_status2, FUN= paste, collapse=' ')
#take one user
#sam <- t2[sample(nrow(t2),4), ]
#remove punctuations and stuffs
ss<- as.vector(t2$status)
ss <- gsub("\\d", "", ss)
ss <- gsub("\\W", " ", ss)
ss <- gsub("[[:punct:]]"," ", ss)
ss <- gsub("bobsnewline", "", ss)
ss <- tolower(iconv(ss,"ISO-8859-1","UTF-8"))
#t_status <- t2$status
#control parameters
#dtm.control <- list(
#        removePunctuation = TRUE,
#        removeNumbers     = TRUE,
#        weighting         = weightTfIdf,
#        wordLengths       = c(3, "inf"))
#        removestopWords   = TRUE,
#dtm1 <- DocumentTermMatrix(corp, control = dtm.control)
#        tolower           = TRUE,
#corp <- Corpus(VectorSource(t_status))
#create dtm for each user, finally I know how to use Tfidf
dtm1 <- create_matrix(ss, language="english", removeNumbers=TRUE, weighting=weightTfIdf)
dtm1 <- create_matrix(ss, language="english", removeNumbers=TRUE, weighting=weightTfIdf)
dtm1<- removeSparseTerms(dtm1, .99)
#turn dtm into a frequency table
freqs <- as.data.frame(inspect(dtm1))
#freqs <- colSums(freqs)
head(t2)
ldaOut.terms <- as.matrix(terms(ldaOut,20))
#just get one topic, a topic has 20 terms
avector <- ldaOut.terms[,1:2]
avector
freqs
freqs[1:10]
library(topicmodels)
require(magrittr)
require(tm)
library(RTextTools)
getwd()
rm(swl)
rm(swl_status2)
library(topicmodels)
require(magrittr)
require(tm)
library(RTextTools)
statusswl <- read.csv("user_all_status_swl.csv", header = T, fill=TRUE,row.names=NULL)
swl_count <- read.csv("user_status_numbers_swl.csv", header = T, fill=TRUE,row.names=NULL)
setwd("../new scripts/")
swl_count <- read.csv("user_status_numbers_swl.csv", header = T, fill=TRUE,row.names=NULL)
swl_status <- merge(statusswl, swl_count, by.x="user_id", by.y="userid", all.x=TRUE)
swl<- read.csv("swl.csv", header = T, fill=TRUE,row.names=NULL)
swl_status2 <- merge(swl_status, swl, by.x="user_id", by.y="userid", all.x=TRUE)
swl_status2 <- swl_status2[complete.cases(swl_status2),]
swl_status2$X.x<- NULL
swl_status2$X.y<- NULL
t2 <- aggregate(status~user_id, swl_status2, FUN= paste, collapse=' ')
topic2000 <- read.csv("2000.csv", header = T, fill=TRUE,row.names=NULL)
topic2000 <- read.csv("2000.csv", header = T, fill=TRUE,row.names=NULL)
topic2001 <- t(topic2000)
#find the word frequency according to the topic list
p4 <- vector()
class(topic2001)
dim(topic2001)
class(t2)
dim(t2)
colnames(t2)
head(t2)
o1<-vector()
o1<-t2[c(1,match(topic2001[,1],names(t2),nomatch=0))]
head(01)
head(o1)
names(t2)
topic2001[,1]
match(topic2001[, i], names(t2), nomatch=0))
match(topic2001[, i], names(t2), nomatch=0)
match(topic2001[, 1], names(t2), nomatch=0)
t2[1,3]
t2[1,2]
head(topic2001)
head(topic2001[,1])
head(topic2001[1,])
head(topic2001[1,1])
topic2000 <- read.csv("2000.csv", header = F, fill=TRUE,row.names=NULL)
topic2001 <- t(topic2000)
topic2001[,1]
p4 <- vector()
o1 <- vector()
o1 <- t2[c(1, match(topic2001[, 1], names(t2), nomatch=0))]
match(topic2001[, 1], names(t2), nomatch=0)
match(topic2001[, 2], names(t2), nomatch=0)
match(topic2001[, 3], names(t2), nomatch=0)
names(t2)
dim(topic2001)
match[topic2001[1,],t2$status,nomatch=0]
class(topic2001)
topic2001[1,]
topic2001[,1]
match(topic2001[,1],t2$status[1])
match(topic2001[,1],t2$status[1],nomatch=1)
match(topic2001[,1],t2$status[1],nomatch=0)
match(topic2001[,1],t2$status[2],nomatch=0)
match(topic2001[,1],t2$status[3],nomatch=0)
match(topic2001[,1],t2$status[4],nomatch=0)
match(topic2001[,2],t2$status[4],nomatch=0)
match(c("bob","dave","ian"),c("hi bob"))
match(c("bob","dave","ian"),c("hi bob","dave"))
strsplit(c("hi bob"))
strsplit(c("hi bob"),sep=" ")
?strsplit
strsplit(c("hi bob"))," ")
strsplit(c("hi bob")," ")
match(c("bob","dave","ian"),strsplit(c("hi bob","dave")," "))
match(c("bob","dave","ian"),strsplit(c("hi bob")," "))
strsplit(c("hi bob")," ")
unlist(strsplit(c("hi bob")," "))
match(c("bob","dave","ian"),unlist(strsplit(c("hi bob")," ")))
p4 <- vector()
for(i in 1:1999) {
o1 <- vector()
o1 <- t2[c(1, match(topic2001[, i], names(t2), nomatch=0))]
if(length(o1) > 2) {
topicCollumn = paste("topic", as.character(i), sep='')
p4[topicCollumn] <- as.data.frame(rowSums(o1[,-1]))
}
}
p4
p4 <- vector()
for(i in 1:1999) {
o1 <- vector()
o1 <- t2[c(1, match(topic2001[, i], names(t2), nomatch=0))]
if(length(o1) > 2) {
topicCollumn = paste("topic", as.character(i), sep='')
p4[topicCollumn] <- as.data.frame(rowSums(o1[,-1]))
}
}
p4
t2 <- aggregate(status~user_id, swl_status2, FUN= paste, collapse=' ')
